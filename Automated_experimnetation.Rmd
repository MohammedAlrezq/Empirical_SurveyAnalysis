---
title: "experiment"
author: "Mohammed Alrezq"
date: "2023-08-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1.2 load data
```{r}
model_11 <- read.csv("mean_data.csv")

# Remove Response.ID and col X from the data 
model_11 <- model_11 |> 
  select(c(-Response.ID, -X))

# Convert all integer columns to numeric
model_11 <- model_11 |> 
  mutate_if(is.integer, as.numeric)
```

## 1.3 Split data to dependent and independet variables 
```{r}
# Dependent variables/items 
model_11_DVs <- model_11 |> 
  select(1:13)
#str(model_11_DVs)
# Independent variables/items 
model_11_IVs <- model_11 |> 
  select(14:42)
#str(model_11_IVs)
```



```{r}
library(psych)

# Function to get items with cross-loadings > threshold
getCrossLoadedItems <- function(fa_result, threshold = 0.32) {
  loadings <- fa_result$loadings
  n_factors <- dim(loadings)[2]
  cross_loaded_items <- character(0)
  
  for (row in 1:nrow(loadings)) {
    item_loadings <- abs(loadings[row, ])
    high_loadings <- item_loadings[item_loadings > threshold]
    if (length(high_loadings) > 1) {
      cross_loaded_items <- c(cross_loaded_items, rownames(loadings)[row])
    }
  }
  return(cross_loaded_items)
}

data <- model_11_IVs  # setting the dataset name
desired_factors <- 3  # target factor loadings

repeat {
  fa_result <- psych::fa(data, nfactors = desired_factors, rotate = "oblimin", fm = "pa", max.iter = 100)
  cross_loaded_items <- getCrossLoadedItems(fa_result)
  
  if (length(cross_loaded_items) == 0) {
    cat("Desired solution achieved!")
    break
  }
  
  # Remove the variable with the highest cross-loading
  item_to_remove <- cross_loaded_items[1]  # removing the first item for simplicity
  data <- data[, !(names(data) %in% item_to_remove)]
  
  cat("Removed:", item_to_remove, "\n")
}

# Print the final result
print(fa_result, cutoff = 0.3, sort = TRUE)

```


# second attemp 
```{r}
# Install and load the required package
#install.packages("psych")
#library(psych)

# Load your dataset - make sure to replace this with your actual dataset import method
#Model_11_IVs <- model_11_IVs

# Run factor analysis for 4, 5, and 6 factors using principle axis factoring
results_list <- list()

for(factors in 4:6) {
  results_list[[as.character(factors)]] <- fa(model_11_IVs, nfactors = factors, 
                                              rotate = "oblimin", 
                                              fm = "pa") # Principle axis factoring
}

# Check results based on your conditions
for(factors in 4:6) {
  cat("\nResults for", factors, "factors:\n")
  loadings <- results_list[[as.character(factors)]]$loadings
  cat("\nLoadings:\n")
  print(loadings, cutoff = 0.4, sort = TRUE) # only show loadings above 0.4 for simplicity
  
  # Check conditions for each factor loading
  satisfied <- TRUE
  
  for(i in 1:ncol(loadings)) {
    column <- loadings[, i]
    # Condition: At least two variables with loading > 0.4
    if(sum(abs(column) > 0.4) < 2) {
      satisfied <- FALSE
      cat("\nFactor", i, "does not have at least two variables with loading > 0.4\n")
    }
    
    # Condition: No cross loadings > 0.32
    if(sum(abs(column) > 0.32 & abs(column) <= 0.4) > 0) {
      satisfied <- FALSE
      cat("\nFactor", i, "has cross-loadings > 0.32\n")
    }
  }
  
  # Condition: communality > 0.4
  communalities <- results_list[[as.character(factors)]]$communalities
  if(any(communalities <= 0.4)) {
    satisfied <- FALSE
    cat("\nNot all communalities are > 0.4\n")
  }
  
  if(satisfied) {
    cat("\nAll conditions satisfied for", factors, "factors!\n")
  } else {
    cat("\nConditions not met for", factors, "factors.\n")
  }
}

```


```{r}
# Install and load the required package
# install.packages("psych")
# library(psych)

# Load your dataset - make sure to replace this with your actual dataset import method
# Model_11_IVs <- read.csv("path_to_your_dataset.csv")

best_solution <- list()
min_removed_items <- ncol(model_11_IVs) # Initialize with the max possible number of removed items

for(factors in 4:6) {
  current_data <- model_11_IVs
  removed_items <- c()
  
  repeat {
    analysis <- fa(current_data, nfactors = factors, rotate = "oblimin", fm = "pa")
    loadings <- analysis$loadings
    
    # Identify cross-loading items
    cross_loading_items <- rownames(loadings)[apply(loadings > 0.32 & loadings < 0.4, 1, sum) > 1]
    
    # Identify weak loading items
    weak_loading_items <- rownames(loadings)[apply(abs(loadings) <= 0.4, 1, sum) == ncol(loadings)]
    
    # Combine problematic items and remove duplicates
    problematic_items <- unique(c(cross_loading_items, weak_loading_items))
    
    # If problematic items are found, remove the first and continue
    if(length(problematic_items) > 0) {
      item_to_remove <- problematic_items[1]
      removed_items <- c(removed_items, item_to_remove)
      current_data <- current_data[, !(names(current_data) %in% item_to_remove)]
    } else {
      break
    }
  }
  
  # If the current solution is better (fewer removed items), save it
  if(length(removed_items) < min_removed_items) {
    best_solution <- list(factors = factors, removed_items = removed_items, analysis = analysis)
    min_removed_items <- length(removed_items)
  }
}

cat("Best solution uses", best_solution$factors, "factors with the following items removed:\n")
print(best_solution$removed_items)
cat("\nLoadings:\n")
print(best_solution$analysis$loadings, cutoff = 0.3, sort = TRUE)

```


### with items > 0.32 cross loading to be remove 
```{r}
# Install and load the required package
# install.packages("psych")
# library(psych)

# Load your dataset - make sure to replace this with your actual dataset import method
# Model_11_IVs <- read.csv("path_to_your_dataset.csv")

best_solution <- list()
min_removed_items <- ncol(model_11_IVs) # Initialize with the max possible number of removed items

for(factors in 4:6) {
  current_data <- model_11_IVs
  removed_items <- c()
  
  repeat {
    analysis <- fa(current_data, nfactors = factors, rotate = "oblimin", fm = "pa")
    loadings <- analysis$loadings
    
    # Identify cross-loading items
    cross_loading_items <- rownames(loadings)[apply(abs(loadings) > 0.32, 1, sum) > 1]
    
    # Identify weak loading items
    weak_loading_items <- rownames(loadings)[apply(abs(loadings) <= 0.4, 1, sum) == ncol(loadings)]
    
    # Combine problematic items and remove duplicates
    problematic_items <- unique(c(cross_loading_items, weak_loading_items))
    
    # If problematic items are found, remove the first and continue
    if(length(problematic_items) > 0) {
      item_to_remove <- problematic_items[1]
      removed_items <- c(removed_items, item_to_remove)
      current_data <- current_data[, !(names(current_data) %in% item_to_remove)]
    } else {
      break
    }
  }
  
  # If the current solution is better (fewer removed items), save it
  if(length(removed_items) < min_removed_items) {
    best_solution <- list(factors = factors, removed_items = removed_items, analysis = analysis)
    min_removed_items <- length(removed_items)
  }
}

cat("Best solution uses", best_solution$factors, "factors with the following items removed:\n")
print(best_solution$removed_items)
cat("\nLoadings:\n")
print(best_solution$analysis$loadings, sort = TRUE)
```


# same as above but set max iteration 
```{r}
# Install and load the required package
# install.packages("psych")
# library(psych)

# Load your dataset - make sure to replace this with your actual dataset import method
# Model_11_IVs <- read.csv("path_to_your_dataset.csv")

best_solution <- list()
min_removed_items <- ncol(model_11_IVs) # Initialize with the max possible number of removed items

max_iterations <- 20 # Define a maximum number of iterations to avoid infinite loops

for(factors in 4:6) {
  current_data <- model_11_IVs
  removed_items <- c()
  iteration_count <- 0 # Reset iteration count
  
  repeat {
    iteration_count <- iteration_count + 1
    analysis <- fa(current_data, nfactors = factors, rotate = "oblimin", fm = "pa")
    loadings <- analysis$loadings
    
    # Identify cross-loading items
    cross_loading_items <- rownames(loadings)[apply(abs(loadings) > 0.32, 1, sum) > 1]
    
    # Identify weak loading items
    weak_loading_items <- rownames(loadings)[apply(abs(loadings) <= 0.4, 1, sum) == ncol(loadings)]
    
    # Combine problematic items and remove duplicates
    problematic_items <- unique(c(cross_loading_items, weak_loading_items))
    
    # If problematic items are found, remove the first and continue
    if(length(problematic_items) > 0) {
      item_to_remove <- problematic_items[1]
      removed_items <- c(removed_items, item_to_remove)
      current_data <- current_data[, !(names(current_data) %in% item_to_remove)]
    } else {
      break
    }

    # Check if maximum iterations reached
    if(iteration_count >= max_iterations) {
      cat("Reached maximum iterations for", factors, "factors.\n")
      break
    }
  }
  
  # If the current solution is better (fewer removed items), save it
  if(length(removed_items) < min_removed_items) {
    best_solution <- list(factors = factors, removed_items = removed_items, analysis = analysis)
    min_removed_items <- length(removed_items)
  }
}

cat("Best solution uses", best_solution$factors, "factors with the following items removed:\n")
print(best_solution$removed_items)
cat("\nLoadings:\n")
print(best_solution$analysis$loadings, sort = TRUE)
```


i have a dataset (the name of my data set is model_11_IVs). i performed scree plot and suggested me to run from 4 to 6 factors and then to check my resutls. I want you to develop me codes where i can experiment 4, 5, and 6 factor using psych package and suing principal axis factor with oblimin rotation. i also look for each variabels loading to be greater than 0.4, crossloading no greater than 0.32, and highest possible varianace explained, and no communalities less than .35. can you develop me a loop codes to run all these conditions in one time 

```{r}
#library(psych)

# Initialize variables to track the best solution
best_solution <- NULL
highest_variance_explained <- 0

# Loop over the desired number of factors
for (n_factors in 4:6) {
  
  # Conduct factor analysis
  fa_result <- fa(model_11_IVs, nfactors = n_factors, rotate = "oblimin", fm = "pa")
  
  # Check communalities 
  good_communalities <- all(fa_result$communalities > 0.35)
  
  # Check factor loadings
  loadings <- fa_result$loadings
  max_loadings <- apply(loadings, 1, max) # Max loading for each variable
  good_loadings <- all(max_loadings > 0.4)
  
  # Check cross-loadings
  crossloadings_check <- function(x) {
    sorted <- sort(abs(x), decreasing = TRUE)
    (sorted[1] > 0.4 & sorted[2] <= 0.32)
  }
  good_crossloadings <- all(apply(loadings, 1, crossloadings_check))
  
  # Variance explained
  variance_explained <- sum(fa_result$values[1:n_factors])
  
  # Save the solution if it meets the criteria and explains more variance than the previous best
  if (good_communalities & good_loadings & good_crossloadings & (variance_explained > highest_variance_explained)) {
    best_solution <- fa_result
    highest_variance_explained <- variance_explained
  }
  
}

# Print the best solution
if (!is.null(best_solution)) {
  print(best_solution)
} else {
  cat("No solution met the criteria.")
}

```

```{r}

# Function to identify variables with cross-loadings > 0.32
cross_loading_issues <- function(loadings_row) {
  sorted <- sort(abs(loadings_row), decreasing = TRUE)
  max_loading <- sorted[1]
  second_max_loading <- sorted[2]
  return(second_max_loading > 0.32)
}

best_solution <- NULL
highest_variance_explained <- 0

# Loop over the desired number of factors
for (n_factors in 4:6) {
  
  current_data <- model_11_IVs
  changes_made <- TRUE
  
  while (changes_made) {
    changes_made <- FALSE
    fa_result <- fa(current_data, nfactors = n_factors, rotate = "oblimin", fm = "pa")
    
    loadings <- fa_result$loadings
    good_communalities <- fa_result$communalities > 0.35
    max_loadings <- apply(loadings, 1, max)
    
    # Variables with cross-loading issues
    problematic_vars <- apply(loadings, 1, cross_loading_issues)
    
    # Combine criteria for removing variables
    remove_vars <- (max_loadings <= 0.4) | (good_communalities == FALSE) | problematic_vars
    
    if (any(remove_vars)) {
      current_data <- current_data[, !names(current_data) %in% names(remove_vars)]
      changes_made <- TRUE
    }
  }
  
  # Variance explained
  variance_explained <- sum(fa_result$values[1:n_factors])
  
  if (variance_explained > highest_variance_explained) {
    best_solution <- fa_result
    highest_variance_explained <- variance_explained
  }
  
}

# Print the best solution
if (!is.null(best_solution)) {
  print(best_solution)
} else {
  cat("No solution met the criteria.")
}

```

```{r}
library(psych)

# Function to identify variables with cross-loadings > 0.32
cross_loading_issues <- function(loadings_row) {
  sorted <- sort(abs(loadings_row), decreasing = TRUE)
  second_max_loading <- sorted[2]
  return(second_max_loading > 0.32)
}

best_solution <- NULL
highest_variance_explained <- 0

# Loop over the desired number of factors
for (n_factors in 4:6) {
  
  current_data <- model_11_IVs
  changes_made <- TRUE
  
  while (changes_made) {
    changes_made <- FALSE
    
    # Check if current_data is empty
    if (ncol(current_data) == 0) {
      cat("All variables removed for", n_factors, "factors. Skipping.\n")
      break
    }
    
    fa_result <- fa(current_data, nfactors = n_factors, rotate = "oblimin", fm = "pa")
    
    loadings <- fa_result$loadings
    good_communalities <- fa_result$communalities > 0.35
    max_loadings <- apply(loadings, 1, max)
    
    # Variables with cross-loading issues
    problematic_vars <- apply(loadings, 1, cross_loading_issues)
    
    # Combine criteria for removing variables
    remove_vars <- (max_loadings <= 0.4) | (good_communalities == FALSE) | problematic_vars
    
    if (any(remove_vars)) {
      # Log which variables are being removed
      removed_var_names <- names(current_data)[remove_vars]
      cat("Removing variables for", n_factors, "factors:", paste(removed_var_names, collapse = ", "), "\n")
      
      current_data <- current_data[, !names(current_data) %in% names(remove_vars)]
      changes_made <- TRUE
    }
  }
  
  # Variance explained
  variance_explained <- sum(fa_result$values[1:n_factors])
  
  if (variance_explained > highest_variance_explained) {
    best_solution <- fa_result
    highest_variance_explained <- variance_explained
  }
  
}

# Print the best solution
if (!is.null(best_solution)) {
  print(best_solution)
} else {
  cat("No solution met the criteria.")
}

```



```{r}
# Function to run PAF with oblimin rotation excluding one item at a time
runPAF <- function(data, item_to_exclude) {
  # Drop the item
  data_sub <- data[, !(names(data) %in% item_to_exclude)]
  
  # Run PAF
  factor_model <- fa(r = data_sub, nfactors = 6, fm = "pa", rotate = "oblimin")
  
  # Remove loadings <= 0.30
  factor_model$loadings[factor_model$loadings <= 0.30] <- 0
  
  return(factor_model)
}

# Loop through all items and run the PAF excluding each one
results_list <- list()
for (item in colnames(data)) {
  results_list[[item]] <- runPAF(data, item)
  
  # Print results for review
  print(paste("Model excluding item:", item))
  print(results_list[[item]])
}

# Now, results_list contains the PAF results for each of the 29 runs, each excluding a different item.

```

```{r}
# Assuming you have already loaded your dataset 'model_11_IVs' and the psych package

# Function to run PAF with oblimin rotation excluding one item at a time
runPAF <- function(data, item_to_exclude) {
  # Drop the item
  data_sub <- data[, !(names(data) %in% item_to_exclude)]
  
  # Run PAF
  factor_model <- fa(r = data_sub, nfactors = 6, fm = "pa", rotate = "oblimin")
  
  # Find columns where the maximum absolute value of loadings is <= 0.30
  col_to_exclude <- apply(abs(factor_model$loadings), 2, max) <= 0.30
  
  # Omit those columns
  factor_model$loadings <- factor_model$loadings[, !col_to_exclude]
  
  return(factor_model)
}

# Loop through all items and run the PAF excluding each one
results_list <- list()
for (item in colnames(model_11_IVs)) {
  results_list[[item]] <- runPAF(model_11_IVs, item)
  
  # Print results for review
  print(paste("Model excluding item:", item))
  print(results_list[[item]])
}

# Now, results_list contains the PAF results for each of the 29 runs, each excluding a different item.

```



```{r}
runPAF <- function(data, item_to_exclude) {
   # Drop the item
   data_sub <- data[, !(names(data) %in% item_to_exclude)]
   
   # Run PAF
   factor_model <- fa(r = data_sub, nfactors = 5, fm = "pa", rotate = "oblimin", max.iter = 100)
   
   return(factor_model)
}

# Loop through all items and run the PAF excluding each one
results_list <- list()
for (item in colnames(model_11_IVs)) {
   results_list[[item]] <- runPAF(model_11_IVs, item)
   
   # Print results for review
   cat(paste("\nModel excluding item:", item, "\n"))
   psych::print.psych(results_list[[item]], cut = 0.3, sort = TRUE)
}

, "", "UND_CNG_22", "EMP_ENG_12", "SCOPE_16"
```

```{r}
set.seed(0000004)
model_11_IV_test1 <- psych::fa(model_11_IVs[, !names(model_11_IVs) %in% c("ORG_CUL_2", "GOAL_CL_25", "GOAL_AL_27", "UND_CNG_22", "EMP_ENG_12", "SCOPE_16")],nfactors = 5, fm = "pa", rotate = "promax", max.iter = 100)
psych::print.psych(model_11_IV_test1, cut = 0.3, sort=TRUE)

```

