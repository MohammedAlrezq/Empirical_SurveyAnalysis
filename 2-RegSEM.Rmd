---
title: "2-RegSEM"
author: "Mohammed Alrezq"
date: "2023-11-01"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, error=FALSE, warning=TRUE}
#install.packages("seminr")
library(seminr)
library(tidyverse)
library(psych)
library(lavaan)
library(semPlot)
library(regsem)
```


# Download data 
```{r}
sem_plsData <- read.csv("sem_plsData.csv")
# remove extra column 
sem_plsData <- sem_plsData |>
  select(-1)
names(sem_plsData)

str(sem_plsData)

#sem_plsData <- scale(sem_plsData)
```
# Check mutlinormality 
```{r}
psych::mardia(sem_plsData)
```

# Measurement and Structual model 
```{r}
meas_model <- '

# measurement model
# Endogenous LVs
Transformational_success =~ EMPL_SAT_9 + ORG_IMP_12 + STAKEH_ACC_4 + EMPL_SKI_8 + DEC_IMP_13 + BUSI_IMP_11 + IMPL_SUCC_1 + EMPL_BEL_10
Deployment_success =~ DEPLOY_6 + ACT_INTG_7
Improvement_Proj_success =~ BUDG_COMP_2 + TASK_COMP_3

# Exogenous LVs 
Improvement_Readiness =~ TOOL_AP_13 + CONTX_CUS_14 + EFT_REQ_15 + EMP_ENG_12 + EXP_CON_20 + CUS_IDEF_26
Sust_Impr_Infrasturcture =~ TRA_EDUC_18 + PAT_RES_24 + WKF_SKL_19 + RES_AVL_4
Supportive_Leadership =~ LD_STL_9 + LD_INV_5 + LD_SUP_1
Meas_based_improvement =~ DAT_QLT_11 + DEF_MEA_7 + PRJ_SEL_6 
Change_awareness =~ EMP_ATT_3 + UND_CNG_22

# structural model
Transformational_success~ Improvement_Readiness+ Sust_Impr_Infrasturcture + Supportive_Leadership + Meas_based_improvement + Change_awareness
Deployment_success~ Improvement_Readiness+ Sust_Impr_Infrasturcture + Supportive_Leadership + Meas_based_improvement + Change_awareness
Improvement_Proj_success~ Improvement_Readiness+ Sust_Impr_Infrasturcture + Supportive_Leadership + Meas_based_improvement + Change_awareness
'


#### Omitting Latent factor covariance
# Improvement_Readiness~~ 0*Sust_Impr_Infrasturcture
# Improvement_Readiness~~ 0*Supportive_Leadership
# Improvement_Readiness~~ 0*Meas_based_improvement
# Improvement_Readiness~~ 0*Change_awareness
# 
# Sust_Impr_Infrasturcture~~0*Supportive_Leadership
# Sust_Impr_Infrasturcture~~0*Meas_based_improvement
# Sust_Impr_Infrasturcture~~0*Change_awareness
# 
# Supportive_Leadership~~0*Meas_based_improvement
# Supportive_Leadership~~0*Change_awareness
# 
# Meas_based_improvement~~0*Change_awareness

#DVs: 
Transformational_success~~Transformational_success
Deployment_success~~Deployment_success
Improvement_Proj_success~~Improvement_Proj_success

# IVs: no co(variance) among IVs
Improvement_Readiness~~Improvement_Readiness
Sust_Impr_Infrasturcture~~Sust_Impr_Infrasturcture
Supportive_Leadership~~Supportive_Leadership
Meas_based_improvement~~Meas_based_improvement
Change_awareness~~Change_awareness
```

# SEM model using ML estimation 
```{r}
# SEM model 
sem_fit <- sem(meas_model, data = sem_plsData)
summary(sem_fit, fit.measures=T, rsquare= T, standardized=T)
#modificationindices(sem_fit, sort. = TRUE)#

# SEM model with bootstrap
# sem_fit_boot <- sem(meas_model, data = sem_plsData, se = "bootstrap" , bootstrap = 1000)
# summary(sem_fit_boot, fit.measures=T, rsquare= T, standardized=T, modindices = T)
# modificationindices(sem_fit, sort. = TRUE)# used to check which parameters can improve SEM fit, but always acceptable 
# to identify all parameters 
#parameterEstimates(sem_fit)

# Paths 
semPaths(sem_fit,whatLabels = "est", style = "ram")

# install.packages("lavaanPlot")
# library(lavaanPlot)
# lavaanPlot(name = "plot", sem_fit)

```

# SEM model using MLR estimation 
```{r}
# # SEM model 
# sem_fit_MLR <- sem(meas_model, data = sem_plsData, estimator = "MLR")# MLR not use with RegSEM
# summary(sem_fit_MLR, fit.measures=T, rsquare= T, standardized=T)
# modificationindices(sem_fit_MLR, sort. = TRUE)#
```

# RegSEM
```{r}
# cross validation using ML (type = "none")
cv_ml <- cv_regsem(sem_fit,
                     pars_pen = c("regressions"),
                                  type = "none",
                                  n.lambda = 40,
                                  jump = 0.05,
                                  lambda.start = 0)

                                  #gradFun = "ram",# used only for use with optMethod="coord_desc".
                                

cv_ml$fits
plot(cv_ml, show.minimum = "BIC", label = TRUE)


# cross validation using LASSO 
lasso_cv <- cv_regsem(sem_fit,
                     type = "lasso",
                     pars_pen = c("regressions"),
                                  gradFun = "ram",
                                  n.lambda = 40,
                                  jump = 0.01, 
                                  lambda.start = 0)
summary(lasso_cv)
#extractMatrices(sem_fit)$A

# this shows lable/number of prameters peanlized 
lasso_cv$pars_pen
# Shows penalized coefficient paths among LVs
lasso_cv$final_pars
# Disply BIC values and best lambda 
lasso_cv$fits

# Plot LASSO that shows the pealized parameters 
par(mar = c(5.1, 4.1, 4.1, 8.1))  # Increase the right margin
plot(lasso_cv, show.minimum = "BIC", label = TRUE)

# BIC PLOT 
bic_values <- head(lasso_cv$fits, 40)

metric_values <- lasso_cv$fits
metric_values


# Extract lambda and BIC values
lambda_values <- metric_values[, "lambda"]
bic_values <- metric_values[, "BIC"]

# Plotting the BIC values against lambda
plot(lambda_values, bic_values, type = 'b', # with a line type of 'b', which means both points and lines are plotted (type = 'b')
     main = "BIC vs. Penalty", 
     xlab = "Penalty (λ)", 
     ylab = "BIC", 
     col = "blue", pch = 19) # pch = 19 will use solid circles for points

smoothed_values <- smooth.spline(lambda_values, bic_values)
lines(smoothed_values, col = "green", lwd = 2) # lwd is the line width

# Computing Schwarz weights from BIC values
# schwarz_weights <- exp((-0.5 * (bic_values - min(bic_values))))
# schwarz_weights <- schwarz_weights / sum(schwarz_weights)
# 
# barplot(schwarz_weights, names.arg = round(lambda_values, 2), main = "Schwarz Weights",
#         xlab = "Penalty (λ)", ylab = "Weights")
#         
```

# Use regsem after identify the value of lambda 
```{r}

lasso_final_model <- regsem(sem_fit,
                            type = "lasso",
                            lambda = .21,# value of lambda 
                            gradFun = "ram")
summary(lasso_final_model)

# model fit chisquare  
lasso_final_model$lav.model


# to check what stored in the object 
str(lasso_final_model)
# Display all measures 
lasso_final_model$lav.model

lavaan_model <- lasso_final_model$lav.model
fit_indices <- lavaan::fitMeasures(lavaan_model)
print(fit_indices)

#Model global measures fit 
chi_square <- fit_indices["chisq"]
p_value <- fit_indices["pvalue"]
df<- fit_indices["df"]
RMSEA <- fit_indices["rmsea"]
CFI <- fit_indices["cfi"]
SRMR <- fit_indices["srmr"]
TLI <- fit_indices["tli"] 

# Combine them into a list
fit_indices_list <- list(
  chi_square = chi_square,
  p_value = p_value,
  degrees_of_freedom = df,
  RMSEA = RMSEA,
  CFI = CFI,
  SRMR = SRMR,
  TLI = TLI)

print(fit_indices_list)
```


